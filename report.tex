\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathtools}
\usepackage[margin=1in]{geometry}
\usepackage{makecell}
\usepackage{wrapfig}
\usepackage{adjustbox,amsmath,caption,color,enumitem,float,graphicx,hyperref,lipsum,multicol,quoting,soul,tabularx}
\title{Analyzing Movies Using Phrase Mining}
\author{Daniel Lee \and Huilai Miao \and Yuxuan Fan}

\begin{document}
\maketitle

\begin{abstract} % What did I do?
Movies are a rich source of human culture from which we can derive insight. Previous work addresses either a textual analysis of movie plots or the use of phrase mining for natural language processing, but not both. Here, we propose a novel analysis of movies by extracting key phrases from movie plot summaries using AutoPhrase, a phrase mining framework. Using these phrases, we analyze movies through 1) an exploratory data analysis that examines the progression of human culture over time, 2) the development and interpretation of a classification model that predicts movie genre, and 3) the development and interpretation of a clustering model that clusters movies. We see that this application of phrase mining to movie plots provides a unique and valuable insight into human culture while remaining accessible to a general audience, e.g., history and anthropology non-experts.
\end{abstract}

\begin{multicols}{2}
\section{Introduction} % What is the problem?
Movies are a rich source of human culture from which we can derive insight through a comprehensive textual analysis of movie plot summaries.

Here, we propose an analysis of movies by extracting key phrases corresponding to discrete entities of human culture. Such an analysis can help us better understand popular topics, public attitudes, and the overall progression and themes of human culture throughout history.

This analysis is novel since we extract human culture from movies, an unconventional source, instead of relying on traditional sources, e.g., historical texts; we expect such a study to provide a unique perspective as a result. In addition, we expect such a study to be especially useful for history and anthropology non-experts, as we extract accessible key phrases that serve as relevant keywords for further research by the reader.

Previous work addresses either a textual analysis of movie plots or the use of phrase mining for natural language processing, but not both. Previous analyses of movies are limited as they tend to simply extract n-grams using raw term frequencies, which often leads to incomplete or spurious phrases, instead of using a dedicated and sophisticated phrase mining framework that is capable of extracting complete and coherent key phrases, such as the \href{https://github.com/shangjingbo1226/AutoPhrase}{AutoPhrase} framework \cite{Shang2018AutomatedPM}.

Here, we use AutoPhrase to explore a novel approach by applying phrase mining to the analysis of movies.

\section{Data}
Our dataset comes from the \href{http://www.cs.cmu.edu/~ark/personas/}{CMU Movie Summary Corpus} \cite{Bamman2013LearningLP} and consists of movie plot summaries extracted from Wikipedia and movie metadata extracted from Freebase.

The dataset contains around 42,000 movies from 1893 to 2014 as seen in Figure \ref{figure:number_movies_per_year_bar_chart}, a sizable dataset for our study. Table \ref{table:variables} describes the variables of the processed dataset.

\begin{figure*}
\caption{Number of movies in the dataset}
\centering
\includegraphics[width=5in]{figures/number_movies_per_year_bar_chart.png}
\label{figure:number_movies_per_year_bar_chart}
\end{figure*}

\begin{table*}
\caption{Dataset variables}
\centering
\begin{tabularx}{.8\textwidth}{llX}
    \textbf{Variable} & \textbf{Description} & \textbf{Example} \\
    \hline
    \texttt{name} & Movie name & \textit{Star Wars Episode IV: A New Hope} \\
    \texttt{date} & Movie release date & \textit{1977-05-25} \\
    \texttt{revenue} & Movie box office revenue (USD) & \textit{775,398,007} \\
    \texttt{runtime} & Movie runtime (minutes) & \textit{122} \\
    \texttt{languages} & Movie languages & \textit{\{English\}} \\
    \texttt{countries} & Movie countries & \textit{\{United States of America\}} \\
    \texttt{genres} & Movie genres & \textit{\{Action, Adventure, Coming-of-age, Family, Fantasy, Science Fiction, Space western\}} \\
    \texttt{summary} & Movie plot summary & \textit{The film begins with an opening crawl explaining that the galaxy is in a state of civil war and that spies for the Rebel Alliance have \ldots} \\
\end{tabularx}
\label{table:variables}
\end{table*}

Although movies can come from different countries and may be in different languages, all of the movie plot summaries are in English (as the dataset is extracted from English Wikipedia).

The variable of focus here is \texttt{summary}, from which we extract key phrases to drive our analysis.

\section{Methods} % How did I approach it?
We first extract key phrases from \texttt{summary} using AutoPhrase \cite{Shang2018AutomatedPM}, a phrase mining framework that extracts high-quality phrases from a given text. We use AutoPhrase for its ability to extract high-quality phrases more effectively than traditional, rudimentary, phrase mining techniques, while maintaining minimal human effort during training.

We first train AutoPhrase on all movie plot summaries in the dataset, then extract the key phrases from each individual summary and add these phrases as a variable in our dataset as seen in Table \ref{table:additional_variables}. Figure \ref{figure:key_phrases_example} gives an example of phrases extracted from a movie plot summary by AutoPhrase.

\begin{table*}
\caption{Added variables}
\centering
\begin{tabularx}{.8\textwidth}{llX}
    \textbf{Variable} & \textbf{Description} & \textbf{Example} \\
    \hline
    \texttt{phrases} & Phrases extracted from \texttt{summary} & \textit{\{alderaan, anakin skywalker, assault, aunt and uncle, bay, c-3po, chewbacca, civil war, commanding officer, darth vader, \ldots\}} \\
\end{tabularx}
\label{table:additional_variables}
\end{table*}

\begin{figure*}
\caption{Example of phrases extracted by AutoPhrase}
\begin{quoting}[leftmargin=.1\textwidth]
\small\textit{The \hl{film} begins with an opening crawl explaining that the \hl{galaxy} is in a \hl{state} of \hl{civil war} and that spies for the \hl{Rebel Alliance} have \hl{stolen} plans to the Galactic Empire's \hl{Death Star}, a \hl{heavily armed} and armored \hl{space station} capable of annihilating an \hl{entire planet}. \hl{Rebel leader} \hl{Princess Leia} is in possession of the plans, but her \hl{ship} is captured by Imperial forces under the command of the evil \hl{lord} \hl{Darth Vader}. Before she is captured, \hl{Leia} hides the plans in the \hl{memory} of an astromech droid called \hl{R2-D2} , along with a holographic \hl{recording}. The small droid flees to the surface of the \hl{desert planet} \hl{Tatooine} with \hl{fellow} protocol droid \hl{C-3PO} . The \hl{droids} are quickly captured by \ldots}
\end{quoting}
\label{figure:key_phrases_example}
\end{figure*}

Nearly all extracted phrases are indeed high-quality and encapsulate ideas, events, objects, and characters in the movie plot well.

Our analysis consists of three parts that build off of these extracted phrases:
\begin{enumerate}
    \item An exploratory data analysis (EDA) that examines the progression of human culture over time.
    \item The development and interpretation of a classification model that predicts movie genre.
    \item The development and interpretation of a clustering model that clusters movies.
\end{enumerate}
We expect the combination of these three methods to give us valuable insight into human culture.
\subsection{EDA}
We perform an EDA to discover how human culture and events have progressed over time. Here, we use statistical signals, i.e., tf-idf, to identify when certain phrases (corresponding to discrete entities of human culture and events) are popular and relevant.

We use tf-idf to measure a phrase's relevance in time where each phrase is a term and each period of time (e.g. a year or decade) is a document. We use sublinear term frequency (tf) scaling to reduce the significance of very common phrases (e.g. ``film'', ``life'') that are uninformative in our analysis.

Here, the tf-idf with sublinear tf scaling for a term $t$ of a document $d$ is given by
$$\text{tf-idf}(t, d) = (1 + \log\text{tf}(t, d)) \cdot \left(\log\frac{1 + n}{\text{1 + df}(t)} + 1\right)$$
where $n$ is the total number of documents and $\text{df}(t)$ is the document frequency of $t$.

Given a TF-IDF vector for each period of time, we then normalize each TF-IDF vector to have a Euclidean norm of 1.

Finally, we define ``top'' phrases as the phrases with the highest TF-IDF values for the corresponding period of time.


\subsection{Classification}
   Classifying movie genres using movie plot summaries examines the power of phrase mining and explores its application in information extraction in movie sector. The results from the classification can also disclose some implicit features of movie genres through important phrases. To obtain ideal results, we construct a baseline model: 
   
   1) Using TF-IDF vectorizer for words embedding
   
   2) Construct multiple logistic regressions inside OneVsRest Classifier for each genre to predict the label. 
   
   3) Evaluating the model use f-1 score. We also use some costumed indicator - percentage of correctly predicted label and percentage of movie that has at least one correctly predicted label
   
%   $$ \text{F-1 Score} = 2*\frac{prediction*recall}{precision+recall}$$
%   $$ \text{percentage of labels} = \frac{\splitedfrac{\text{sum of correctly predicted}}{\text{labels over all movies}}}{\text{total number of labels over all movies}}$$
   
%   $$ \text{percentage of movies} = \frac{\text{number of movies that has at least one label that is predicted right by the model}}{\text{total number of movies}}$$
   
   
   
   We further improve our model in following ways: 
   
   1) We try out different algorithms in OneVsRest Classifier including LinearSVC and Multi-linear Perceptron classifier. 
   
   2) We perform GridSearch for hyper-parameters tuning, changing different loss function and different regularization penalty for best performance.
   
   We also construct the text feature in two ways
   
   1) Use all non-stopwords in plot summaries
   
   2) Use only extracted phrases of these summaries by Autophrase.
   
   We can compare the results from these two approaches to explore the contribution of phrases to the model.
   
   Finally, to better evaluate our model, we will interpret the coefficients of words of classifiers to see what words or phrases that our predictions mostly rely on. We then generate plots for the words/phrases rank to evaluate the model using our understanding of genre and see if the result can tell us anything more about the genre that we do not know before. 
   
   
   
\subsection{Clustering}

\begin{figure*}
\caption{The clustering pipeline}
\centering
\includegraphics[width=5in]{figures/clustering_pipeline.png}
\label{figure:clustering_pipeline}
\end{figure*}

We build a clustering pipeline on the movie plot summaries to discover relationships between movies in a marginally supervised perspective. As shown in Figure \ref{figure:clustering_pipeline}, our clustering pipeline contains three major components: (1) build and fine-tune a sentence transformer to acquire document embeddings, (2) pick representative sentences to condense plot summaries, and (3) cluster document embeddings.

\subsubsection{Model}
We propose to estimate the document embeddings based on a pre-trained sentence transformer (\cite{reimers-gurevych-2019-sentence}). Experiments in \cite{aharoni-goldberg-2020-unsupervised} show that the contextualized embeddings generated by pre-trained language models have the capability to preserve domain information. Compared with vanilla transformer networks, sentence transformers are further tailored to estimate contextualized sentence embeddings for semantic similarity tasks (\cite{reimers-gurevych-2019-sentence}). Therefore, the sentence transformer is the strongest out-of-the-box model we can utilize.

Since the sentence transformer expects sentences as input, we split each summary into sentences, acquire an embedding for each sentence, and average the embeddings to form document embeddings.

\begin{figure*}
\caption{Number of sentences per document (plot summary)}
\centering
\includegraphics[width=5in]{figures/sents_per_doc.png}
\label{figure:sents_per_doc}
\end{figure*}

\subsubsection{Condense plot summaries}
As shown in Figure \ref{figure:sents_per_doc}, the distribution of the number of sentences in each movie summary is a long-tailed distribution, where 46.05\% of summaries have more than 10 sentences. Since the transformer truncates the document to a fixed length, the embeddings acquired from the model cannot fully capture the semantics of long summaries. Therefore, it is necessary to condense the movie summaries while preserving most of the gist.

We propose to rank the importance of the sentences and choose sentences with top-k importance to represent the entire summary. Here, we define the importance as the average sublinear TF-IDF score, where the dictionary of terms is only the quality phrases. Under this notion of importance, sentences with no quality phrases have an importance score of 0, and sentences with more uncommon quality phrases have a higher importance score. If the document has fewer than $k$ sentences, we keep all sentences. If the document contains no quality phrases, we sample $k$ sentences randomly. To acquire the document embeddings, we only use representative sentences instead of all sentences.

\subsubsection{Fine-tuning}
Fine-tuning a pre-trained language model with a specific downstream task is a common practice to enhance the model performance. In our clustering pipeline, we use semantic similarity as the downstream task, since we expect documents with similar meanings to have closer embeddings, and vice versa. 
For two pairs of sentences, we determine the similarity by finding whether the genres associated with these sentences have overlap. To generate the training dataset, we iteratively sample sentence pairs until the training dataset contains at least $n$ pairs, where half of the pairs have positive labels and the other half have negative labels. In each iteration, the algorithm samples two documents from the dataset, generates the binary label based on their genres, and selects $k$ sentence pairs from two documents.

We use the Contrastive Loss (\cite{1640964}) as the fine-tune target, since it aims to decrease the distance between sentence embeddings of similar sentence pairs and increase the distance between sentence embeddings of dissimilar sentence pairs.


\subsubsection{Cluster embeddings}
Following the practices in \cite{aharoni-goldberg-2020-unsupervised}, we first reduce the dimensions of embeddings to 50 with PCA, then cluster the dimension-reduced embeddings using Gaussian Mixture Model (GMM). \cite{aharoni-goldberg-2020-unsupervised} explained that the mixture model is more suitable since we can view each document embedding as from a mixture of different domain distributions, and applying PCA to the embeddings accelerates the training process while marginally damaging the performance.



\section{Results} % What did I find out?
\subsection{EDA}
Figure \ref{figure:top_phrases_by_decade} shows top phrases by decade, where top phrases are defined earlier as the phrases with the highest tf-idf values for the corresponding decade.

\begin{figure*}
\caption{Top phrases by decade, with corresponding highest-grossing movie}
\centering
\includegraphics[width=.95\textwidth]{figures/top_phrases_by_decade_bar_chart.png}
\label{figure:top_phrases_by_decade}
\end{figure*}

To provide context, we annotate each phrase with the name and year of the highest-grossing movie out of all movies that contain that phrase in that decade. In the case of a tie in gross revenue, we pick the movie with the earlier release date.

We now examine the results by decade:
\begin{itemize}
    \item \textit{1900s}: It is important to note that the earliest commercial movie screening occurred in 1895 and thus movies were still a relatively new phenomenon in the early 1900s. Top phrases in this decade do not appear to be very salient but do reference objects that may be associated with the early 20th century such as ``horse'' and ``train''.
    \item \textit{1910s}: Many of the top phrases and their corresponding top movies in this decade relate to Australia, which is reasonable since the Commonwealth of Australia was established in 1901. This includes the phrases ``bushranger'' (an outlaw living in the Australian bush), ``Melbourne'', and ``Australian'' and the movies \textit{The Squatter's Daughter}, \textit{Moora Neya, or The Message of the Spear}, \textit{Mates from the Murrumbidgee}, \textit{Moonlite}, and \textit{For Australia}.
    \item \textit{1920s}: The most salient top phrases in this decade, ``Stan and Ollie'' and ``Laurel and Hardy'', refer to the internationally famous comedy duo Stan Laurel and Oliver Hardy, whose act was active from the 1920s to 1950s.
    \item \textit{1930s}: We see the appearance of movie characters Alfafa, Buckwheat, Spanky, and Stymie from the \textit{Our Gang} comedy series, Betty Boop and Bimbo from the \textit{Talkartoon} and \textit{Betty Boop} cartoon series, actors Robert Armstrong in \textit{King Kong} and Edward Arnold in \textit{Mr. Smith Goes to Washington}, and the reappearance of Stan and Ollie.
    \item \textit{1940s}: Many of the top phrases and their corresponding top movies in this decade relate to World War II, fought from 1939 to 1945, including the phrases ``World War II'' and ``Nazi'' and the movies \textit{Foreign Correspondent}, \textit{The Best Years of Our Lives}, \textit{The White Cliffs of Dover}, and \textit{Hitler's Children}. We see the appearance of movie characters Mammy Two Shoes from the the \textit{Tom and Jerry} cartoon series, Daffy Duck from the \textit{Looney Tunes} and \textit{Merrie Melodies} cartoon series, actors Moe and Larry, the two mainstay members of The Three Stooges, a famous comedy team active from the 1920s to 1970s (the third stooge changed multiple times throughout the team's history) and Harry Davenport in \textit{Foreign Correspondent}, and the reappearance of Buckwheat.
    \item \textit{1950s}: We continue to see phrases and movies relating to World War II, including the movie \textit{Giant}. We see the appearance of movie characters The Bowery Boys and the reappearance of Moe and Larry. We also see the phrase ``Puddy Tat'' from Tweety's catchphrase ``I Taut I Taw a Puddy-Tat'' from the Sylvester and Tweety cartoons and the phrase ``mousehole'' from the \textit{Tom and Jerry} cartoon series.
    \item \textit{1960s}: We continue to see phrases and movies relating to World War II. We see the use of the phrase ``beatnik'', a media stereotype prevalent from the 1940s to 1960s associated with the nonconformist Beat Generation literary movement in the post-war era, whose elements were later incorporated into the hippie movement and other counterculture movements. We see the appearance of movie characters Speedy Gonzales from the \textit{Looney Tunes} and \textit{Merrie Melodies} cartoon series.
    \item \textit{1970s}: Many of the top phrases and their corresponding top movies in this decade relate to the Vietnam War, fought from 1955 to 1975, including the phrases ``Vietnam'' and ``Vietnam War''. Other top phrases and their corresponding top movies relate to martial arts, including the phrases ``kung fu'' and ``Shaolin''. During this time, martial arts movies rose in popularity, such as those featuring Bruce Lee, which helped lead to an increase in Asian and Asian American representation in cinema. We see the appearance of movie characters Tora-san from the \textit{Otoko wa Tsurai yo} Japanese film series and film historian and critic Stuart Galbraith IV.
    \item \textit{1980s}: We continue to see phrases and movies relating to the Vietnam War. We see the appearance of America's CIA, founded in 1947, and the Soviet Union's KGB, formed in 1954, two opposing security/intelligence agencies whose appearance in movies may have been popularized by the Cold War during this time period. We see the appearance of Indian cinema in the form of actors Mithun Chakraborty in \textit{Kismet}, considered to be one of the foundational films of Bollywood, Lizy in \textit{Arante Mulla Kochu Mulla}, and Rati Agnihotri in \textit{Ullasa Paravaigal}. We see the reappearance of Tora-San and Stuart Galbraith IV.
    \item \textit{1990s}: The top phrase in this decade is ``HIV'', which was first clinically observed in 1981, triggering much of the early HIV/AIDS research in the 1980s. This development may have led to HIV/AIDS being recognized by popular culture in the following years; in fact, the top movie corresponding to ``HIV'', \textit{Philadelphia}, was one of the first mainstream Hollywood movies to mention HIV/AIDS. We continue to see phrases and movies relating to the CIA and Vietnam War. We see technologies that may have been more readily accessible to consumers in the late 20th century, such as ``video'', ``tv'', ``videotape'', and ``answering machine''. We see the appearance of movie character Simran Singh in another Bollywood movie, \textit{Dilwale Dulhania Le Jayenge} and the reappearance of Mithun.
    \item \textit{2000s}: The top phrase in this decade is ``heart attack''. It is unclear why, but as a continuously leading cause of death since the mid-20th century, cardiovascular disease may have been especially prevalent in popular culture in this time period. We see top phrases relating to the September 11 attacks, namely ``September 11'' and ``9/11''. We continue to see technologies that are relevant to consumers in this time period, namely ``laptop'' and ``internet''. We see the appearance of ``hip hop'', which became the top-selling music genre by 1999 and continued to become increasingly popular throughout the 2000s. We see the appearance of actors Sneha in \textit{Autograph} and John Abraham in \textit{Water}.
    \item \textit{2010s}: We come to the most recent decade in the dataset. ``Heart attack'' continues to be the top phrase in this decade. We continue to see technologies that are relevant to consumers in this time period, namely ``Facebook'' and ``internet''. Indian cinema continues its presence with the appearance of actor N. Santhanam in \textit{Thillalangadi} and the reappearance of Sneha in \textit{Theeradha Vilaiyattu Pillai}.
\end{itemize}

We can see that examining and researching top phrases over time gives us valuable insight into human culture and its public attitudes, events, people, ideas, etc. Phrase mining and the use of tf-idf automatically identifies relevant keywords in a way that would be difficult to do manually or by using traditional text mining methods.

Figure \ref{figure:top_phrases_by_year} in \nameref{appendix} goes into much finer detail by showing top phrases by year instead of decade and is also available as an \href{https://www.youtube.com/watch?v=8aOob6iJO5Y}{animation}. There, we observe a similar trend of top phrases across time but also observe phrases that are peculiar to each year.

 \begin{figure*}
\caption{final model result with summary text features}
\centering
\adjincludegraphics[width=5in,trim=0 {.01\height} 0 0,clip]{figures/final model - summary text.png}
\label{figure:classification with summary text}
\end{figure*}

\begin{figure*}
\caption{final model result with phrase features}
\centering
\includegraphics[width=5in]{figures/final model - phrases.png}
\label{figure:classification with phrase}
\end{figure*}

\subsection{Classification}
Our baseline had a result F-1 score 0.332 using whole summaries as feature and 0.29 using phrases. Our final model had a result F-1 score of 0.407 using summaries and 0.364 using phrases.

\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\thead{model}&\thead{feature}&\thead{F-1 score} & \thead{label \%} & \thead{movie\%} \\
\hline
 \thead{baseline}&\thead{summary \\text} & \thead{0.33} &\thead{0.043} &\thead{0.12}\\
&\thead{phrases} & \thead{0.29} & \thead{0.038} & \thead{0.11}\\
\hline
\thead{final \\model} & \thead{summary text}&\thead{0.41} & \thead{0.062} & \thead{0.13}\\
& \thead{phrases}& \thead{0.36} & \thead{0.053} & \thead{0.13}\\
\hline 
\end{tabular} 
\end{center}



 We extract the coefficients of words from the classifiers to understand what words matter most for each genre in our classification. It helps to evaluate the model as well as deliver some insights on genre prediction. The plot shows the top 20 words that has the largest coefficients, thus the highest significance to the that genre. Due to lacking of ground truth to compare with, we will put forward some interesting findings from Figure \ref{figure:classification with summary text} and Figure \ref{figure:classification with phrase} :
 
 

\begin{itemize}
    \item  \textit{Drama}: Using summary text, we found some female names like Helene, Carmen, Johann in the plots. Our model seems to place some importance in the Female name when predicting Drama movies. While using phrases, we found more animals in the top phrases, like goa, cattle, guinea pig, etc. There are more negative words/phrases as well, like exorcism, flatulence, local-mob, domestic violence etc. 
    \item \textit{Comedy}: Using summary text, interestingly, we found some male names in the top words, like Elmo, Davey, Jones, Doug etc. Other words mostly human behaviors or status like hurry, ashamed, dig, chop, etc. Using phrase, we find the phrases and words are more region related, like Ethiopian, Baltimore, British Rag etc. There are also lots of hostile words like hostage, homophobia, ensuing battle, blockade, destructive, etc. One hypothesis is that lots of comedies use contradictions to provoke funny scenes. 
    \item \textit{Romance}: Using summary text, we still see lots of people names. There are also words describing relation status like deserted and attracted. Using phrases, there appear to be some locations and community like Havana, Houston, Rojo, death squad, and firing squad. The results here seem quite deviated from what we expected.
    \item \textit{Thriller}: Using summary text, there are words with uncanny meanings like alien, immortality, bury, deadly. Using phrases, there are words related to criminal scenes like drug cartel, captured and imprisoned.
\end{itemize}

\subsection{Clustering}

To examine our clustering pipeline, we cluster all vectors into 200 clusters and perform analysis on the output. We choose this number of clusters as the target since each cluster will roughly contain 200 movies, which is a reasonable size to derive fine-grained semantic units.

Since the original dataset contains more than 300 genres and each document contains multiple genres, assigning the cluster label with the most common label within the cluster (\cite{aharoni-goldberg-2020-unsupervised}) is not feasible. Instead, we choose to determine the semantics of the cluster using multiple heuristics, including quality phrase distributions and the overlaps with existing genres.

\textbf{Quality phrases.} To preserve the generality, we remove all phrases that occur in less than 100 documents. Then, for each phrase in each cluster, we calculate the document frequency within the cluster relative to its document frequency in the entire dataset. In other words, when a phrase occurs more frequently in this cluster than other clusters, we consider this phrase as a representative of this cluster. We rank the relative document frequencies of quality phrases in each cluster and pick the top 5 phrases to represent the cluster. 



Table \ref{table:cluster_rep_quality_phrases} in the \nameref{appendix} shows some examples of the representative quality phrases. From the examples, we can observe that many clusters can capture meanings that can be easily identified. We can infer that example 1 contains movies about special forces, example 2 is about martial arts in Asia, and example 3 is about sports. However, we cannot identify the specific topic for some clusters like examples 4 and 5.

\textbf{Genres.} We repeat the same process as examining the quality phrase memberships to examine the overlaps with genres. Table \ref{table:cluster_rep_genres} in the \nameref{appendix} shows some examples of the genre distributions. We can observe that many clusters (like example 1, 2, 3) gather the movies with similar genres together with only a few hints about similarity during the fine-tuning process. However, for clusters like examples 4 and 5, we cannot identify an obvious topic.

We can see that the document embeddings can capture the semantics of the summaries to some extent, and feeding them to a clustering pipeline give us insights about the relationships between movies. By defining heuristics and summarize from each cluster, we can observe more connections that are hidden from the existing human crafted features.


\section{Discussion} % What did it mean?
In this paper, we apply phrase mining to movie plots, a novel approach for the textual analysis of movies, for a unique insight into human culture.

In the EDA investigation, we use statistical signals to select the most relevant phrases describing each time period. In the classification investigation, we explore different classification methods for best genre prediction performance. In the clustering investigation, we utilize quality phrases and pre-trained language models to discover the relationship between movies in a nearly unsupervised approach.

In each of these investigations, we demonstrate phrase mining's effectiveness in producing valuable insight into human culture.

For future work, we may consider omitting movie character and/or actor names from the top phrases, as movie characters and actors, unless historically significant, are not central to our analysis of human culture.

\bibliographystyle{plain} % Who did I cite?
\nocite{10.1145/2723372.2751523}
\bibliography{report}

\section{Appendix} \label{appendix} % Details!

\begin{figure*}
\caption{Top phrases by year}
\centering
\adjincludegraphics[width=\textwidth,trim=0 {.53\height} 0 0,clip]{figures/top_phrases_by_year_bar_chart.png}
\label{figure:top_phrases_by_year}
\end{figure*}

\begin{figure*}
\ContinuedFloat
\centering
\adjincludegraphics[width=\textwidth,trim=0 0 0 {.47\height},clip]{figures/top_phrases_by_year_bar_chart.png}
\end{figure*}

\begin{table*}
\caption{Examples of representative quality phrases in clusters}
\centering
\begin{tabularx}{.8\textwidth}{llX}
    \textbf{E.g.} & \textbf{Quality Phrases} \\
    \hline
    \texttt 1 & cia, sniper, helicopter, swat, laser, ...\\
    \texttt 2 & kung fu, martial arts, monks, shanghai, thailand, ...\\
    \texttt 3 & championship, basketball, coach, academic, baseball, ...\\
    \texttt 4 & publisher, tokyo, province, economy, fever, ...\\
    \texttt 5 & santa claus, fairy, frog, daffy, porky, ...\\
\end{tabularx}
\label{table:cluster_rep_quality_phrases}
\end{table*}

\begin{table*}
\caption{Examples of representative genres in clusters}
\centering
\begin{tabularx}{.8\textwidth}{llX}
    \textbf{E.g.} & \textbf{Genres} \\
    \hline
    \texttt 1 & Slapstick, Sex comedy, Musical comedy, Comedy of manners, Comedy of Errors, ...\\
    \texttt 2 & Courtroom Drama, Docudrama, Erotic Drama, Melodrama, Erotic thriller, ...\\
    \texttt 3 & Stop motion, Children's Fantasy, Computer Animation, Animation, Family-Oriented Adventure, ...\\
    \texttt 4 & Musical Drama, Ensemble, Experimental, Biography, Gay, ...\\
    \texttt 5 & Comedy of manners, Domestic Comedy, Anime, Sports, Teen, ...\\
\end{tabularx}
\label{table:cluster_rep_genres}
\end{table*}

 \begin{figure*}
\caption{baseline model result with summary text features}
\centering
\includegraphics[width=5in]{figures/baseline - summary text.png}
\label{figure:classification with summary text baseline}
\end{figure*}

\begin{figure*}
\caption{baseline result with phrase features}
\centering
\includegraphics[width=5in]{figures/baseline - phrases.png}
\label{figure:classification with phrase baseline}
\end{figure*}

\end{multicols}

\end{document}
